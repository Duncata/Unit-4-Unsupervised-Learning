{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import state_union, stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4.5 Challenge - Build Your Own NLP Model\n",
    "\n",
    "For this challenge, you will need to choose a corpus of data from nltk or another source that includes categories you can predict and create an analysis pipeline that includes the following steps:\n",
    "\n",
    "1. Data cleaning / processing / language parsing\n",
    "2. Create features using two different NLP methods: For example, BoW vs tf-idf.\n",
    "3. Use the features to fit supervised learning models for each feature set to predict the category outcomes.  Use cross-validation and determine whether one model performed better.\n",
    "5. Pick one of the models and try to increase accuracy by at least 5 percentage points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abc.zip', 'alpino', 'alpino.zip', 'biocreative_ppi', 'biocreative_ppi.zip', 'brown', 'brown.zip', 'brown_tei', 'brown_tei.zip', 'cess_cat', 'cess_cat.zip', 'cess_esp', 'cess_esp.zip', 'chat80', 'chat80.zip', 'city_database', 'city_database.zip', 'cmudict', 'cmudict.zip', 'comparative_sentences', 'comparative_sentences.zip', 'comtrans.zip', 'conll2000', 'conll2000.zip', 'conll2002', 'conll2002.zip', 'conll2007.zip', 'crubadan', 'crubadan.zip', 'dependency_treebank', 'dependency_treebank.zip', 'dolch', 'dolch.zip', 'europarl_raw', 'europarl_raw.zip', 'floresta', 'floresta.zip', 'framenet_v15', 'framenet_v15.zip', 'framenet_v17', 'framenet_v17.zip', 'gazetteers', 'gazetteers.zip', 'genesis', 'genesis.zip', 'gutenberg', 'gutenberg.zip', 'ieer', 'ieer.zip', 'inaugural', 'inaugural.zip', 'indian', 'indian.zip', 'jeita.zip', 'kimmo', 'kimmo.zip', 'knbc.zip', 'lin_thesaurus', 'lin_thesaurus.zip', 'machado.zip', 'mac_morpho', 'mac_morpho.zip', 'masc_tagged.zip', 'movie_reviews', 'movie_reviews.zip', 'mte_teip5', 'mte_teip5.zip', 'names', 'names.zip', 'nombank.1.0.zip', 'nonbreaking_prefixes', 'nonbreaking_prefixes.zip', 'nps_chat', 'nps_chat.zip', 'omw', 'omw.zip', 'opinion_lexicon', 'opinion_lexicon.zip', 'panlex_swadesh.zip', 'paradigms', 'paradigms.zip', 'pil', 'pil.zip', 'pl196x', 'pl196x.zip', 'ppattach', 'ppattach.zip', 'problem_reports', 'problem_reports.zip', 'product_reviews_1', 'product_reviews_1.zip', 'product_reviews_2', 'product_reviews_2.zip', 'propbank.zip', 'pros_cons', 'pros_cons.zip', 'ptb', 'ptb.zip', 'qc', 'qc.zip', 'reuters.zip', 'rte', 'rte.zip', 'semcor.zip', 'senseval', 'senseval.zip', 'sentence_polarity', 'sentence_polarity.zip', 'sentiwordnet', 'sentiwordnet.zip', 'shakespeare', 'shakespeare.zip', 'sinica_treebank', 'sinica_treebank.zip', 'smultron', 'smultron.zip', 'state_union', 'state_union.zip', 'stopwords', 'stopwords.zip', 'subjectivity', 'subjectivity.zip', 'swadesh', 'swadesh.zip', 'switchboard', 'switchboard.zip', 'timit', 'timit.zip', 'toolbox', 'toolbox.zip', 'treebank', 'treebank.zip', 'twitter_samples', 'twitter_samples.zip', 'udhr', 'udhr.zip', 'udhr2', 'udhr2.zip', 'unicode_samples', 'unicode_samples.zip', 'universal_treebanks_v20.zip', 'verbnet', 'verbnet.zip', 'verbnet3', 'verbnet3.zip', 'webtext', 'webtext.zip', 'wordnet', 'wordnet.zip', 'wordnet_ic', 'wordnet_ic.zip', 'words', 'words.zip', 'ycoe', 'ycoe.zip']\n"
     ]
    }
   ],
   "source": [
    "#See Corpus\n",
    "import os\n",
    "import nltk.corpus\n",
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1945-Truman.txt',\n",
       " '1946-Truman.txt',\n",
       " '1947-Truman.txt',\n",
       " '1948-Truman.txt',\n",
       " '1949-Truman.txt',\n",
       " '1950-Truman.txt',\n",
       " '1951-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1954-Eisenhower.txt',\n",
       " '1955-Eisenhower.txt',\n",
       " '1956-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1958-Eisenhower.txt',\n",
       " '1959-Eisenhower.txt',\n",
       " '1960-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1962-Kennedy.txt',\n",
       " '1963-Johnson.txt',\n",
       " '1963-Kennedy.txt',\n",
       " '1964-Johnson.txt',\n",
       " '1965-Johnson-1.txt',\n",
       " '1965-Johnson-2.txt',\n",
       " '1966-Johnson.txt',\n",
       " '1967-Johnson.txt',\n",
       " '1968-Johnson.txt',\n",
       " '1969-Johnson.txt',\n",
       " '1970-Nixon.txt',\n",
       " '1971-Nixon.txt',\n",
       " '1972-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1974-Nixon.txt',\n",
       " '1975-Ford.txt',\n",
       " '1976-Ford.txt',\n",
       " '1977-Ford.txt',\n",
       " '1978-Carter.txt',\n",
       " '1979-Carter.txt',\n",
       " '1980-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1982-Reagan.txt',\n",
       " '1983-Reagan.txt',\n",
       " '1984-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1986-Reagan.txt',\n",
       " '1987-Reagan.txt',\n",
       " '1988-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1990-Bush.txt',\n",
       " '1991-Bush-1.txt',\n",
       " '1991-Bush-2.txt',\n",
       " '1992-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1994-Clinton.txt',\n",
       " '1995-Clinton.txt',\n",
       " '1996-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '1998-Clinton.txt',\n",
       " '1999-Clinton.txt',\n",
       " '2000-Clinton.txt',\n",
       " '2001-GWBush-1.txt',\n",
       " '2001-GWBush-2.txt',\n",
       " '2002-GWBush.txt',\n",
       " '2003-GWBush.txt',\n",
       " '2004-GWBush.txt',\n",
       " '2005-GWBush.txt',\n",
       " '2006-GWBush.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Presidential State of the Unions file ids\n",
    "state_union.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the first speech of Truman and Eisenhower\n",
    "truman = state_union.raw('1945-Truman.txt')\n",
    "eisenhower = state_union.raw('1953-Eisenhower.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse using Spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "truman_doc = nlp(truman)\n",
    "eisenhower_doc = nlp(eisenhower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRESIDENT HARRY S. TRUMAN'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS\n",
      " \n",
      "April 16, 1945\n",
      "\n",
      "Mr. Speaker, Mr. President, Members of the Congress:\n",
      "It is with a heavy heart that I stand before you, my friends and colleagues, in the Congress of the United States.\n",
      "Only yesterday, we laid to rest the mortal remains of our beloved President, Franklin Delano Roosevelt. At a time like this, words are inadequate. The most eloquent tribute would be a reverent silence.\n",
      "Yet, in this decisive hour, when world events are moving so rapidly, our silence might be misunderstood and might give comfort to our enemies.\n",
      "In His infinite wisdom, Almighty God has seen fit to take from us a great man who loved, and was beloved by\n",
      "\n",
      "Truman speech length: 2194\n",
      "\n",
      " PRESIDENT DWIGHT D. EISENHOWER'S ANNUAL MESSAGE TO THE CONGRESS ON THE STATE OF THE UNION\n",
      " \n",
      "February 2, 1953\n",
      "\n",
      "Mr. President, Mr. Speaker, Members of the Eighty-third Congress:\n",
      "I welcome the honor of appearing before you to deliver my first message to the Congress.\n",
      "It is manifestly the joint purpose of the congressional leadership and of this administration to justify the summons to governmental responsibility issued last November by the American people. The grand labors of this leadership will involve:\n",
      "Application of America's influence in world affairs with such fortitude and such foresight that it will deter aggression and eventually secure peace;\n",
      "Establishment of a national administration of such integrity and such efficiency that its honor at home will ensure respect abroad;\n",
      "Encouragement of those incentives that inspire creative initiative in\n",
      "\n",
      "eisenhower_doc speech length: 7922\n"
     ]
    }
   ],
   "source": [
    "# Let look at excerpts from each speech\n",
    "print(truman_doc[:150])\n",
    "print('\\nTruman speech length:', len(truman_doc))\n",
    "\n",
    "print('\\n', eisenhower_doc[:150])\n",
    "print('\\neisenhower_doc speech length:', len(eisenhower_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(PRESIDENT, HARRY, S., TRUMAN, 'S, ADDRESS, BE...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(It, is, with, a, heavy, heart, that, I, stand...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Only, yesterday, ,, we, laid, to, rest, the, ...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(At, a, time, like, this, ,, words, are, inade...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(The, most, eloquent, tribute, would, be, a, r...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Yet, ,, in, this, decisive, hour, ,, when, wo...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(In, His, infinite, wisdom, ,, Almighty, God, ...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(No, man, could, possibly, fill, the, tremendo...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(No, words, can, ease, the, aching, hearts, of...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(The, world, knows, it, has, lost, a, heroic, ...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(Tragic, fate, has, thrust, upon, us, grave, r...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(We, must, carry, on, .)</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(Our, departed, leader, never, looked, backwar...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(He, looked, forward, and, moved, forward, .)</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(That, is, what, he, would, want, us, to, do, .)</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(That, is, what, America, will, do, ., \\n)</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(So, much, blood, has, already, been, shed, fo...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(Today, ,, the, entire, world, is, looking, to...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(Such, a, leadership, requires, vision, ,, cou...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(It, can, be, provided, only, by, a, united, n...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(With, great, humility, I, call, upon, all, Am...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(I, want, in, turn, to, assure, my, fellow, Am...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(That, is, my, duty)</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(and, I, shall, not, shirk, it, ., \\n)</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(So, that, there, can, be, no, possible, misun...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(We, are, deeply, conscious, of, the, fact, th...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(Having, to, pay, such, a, heavy, price, to, m...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(To, settle, for, merely, another, temporary, ...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(Our, demand, has, been, ,, and, it, remains, ...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(We, will, not, traffic, with, the, breakers, ...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>(The, Food, and, Drug, Administration, should,...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>(The, invalidation, of, these, inspections, by...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>(These, must, be, promptly, corrected, ., \\n)</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>(I, am, well, aware, that, beyond, these, few,...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>(The, health, and, housing, needs, of, our, pe...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>(Involved, are, the, solvency, of, the, whole,...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>(To, bring, clear, purpose, and, orderly, proc...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>(I, shall, shortly, send, you, specific, recom...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>(I, repeat, that, there, are, many, important,...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>(Among, these, is, our, great, and, growing, b...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>(America, has, traditionally, been, generous, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>(These, millions, remain, close, to, all, our,...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>(Proper, care, of, our, uniformed, citizens, a...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>(We, have, surveyed, briefly, some, problems, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>(The, hope, of, freedom, itself, depends, ,, i...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>(We, must, be, strong, in, arms, .)</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>(We, must, be, strong, in, the, source, of, al...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>(We, all, --, workers, and, farmers, ,, foreme...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>(We, must, be, strong, ,, above, all, ,, in, t...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>(We, must, be, devoted, with, all, our, heart,...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>(We, must, know, that, each, of, these, values...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>(We, must, know, that, freedom, expresses, its...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>(As, our, heart, summons, our, strength, ,, ou...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>(There, is, ,, in, world, affairs, ,, a, stead...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>(There, is, ,, in, our, affairs, at, home, ,, ...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>(This, way, must, avoid, government, by, burea...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>(In, every, area, of, political, action, ,, fr...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>(In, this, spirit, must, we, live, and, labor, :)</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>(confident, of, our, strength, ,, compassionat...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>(In, this, spirit, ,, let, us, together, turn,...</td>\n",
       "      <td>Eisenhower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0           1\n",
       "0    (PRESIDENT, HARRY, S., TRUMAN, 'S, ADDRESS, BE...      Truman\n",
       "1    (It, is, with, a, heavy, heart, that, I, stand...      Truman\n",
       "2    (Only, yesterday, ,, we, laid, to, rest, the, ...      Truman\n",
       "3    (At, a, time, like, this, ,, words, are, inade...      Truman\n",
       "4    (The, most, eloquent, tribute, would, be, a, r...      Truman\n",
       "..                                                 ...         ...\n",
       "475  (This, way, must, avoid, government, by, burea...  Eisenhower\n",
       "476  (In, every, area, of, political, action, ,, fr...  Eisenhower\n",
       "477  (In, this, spirit, must, we, live, and, labor, :)  Eisenhower\n",
       "478  (confident, of, our, strength, ,, compassionat...  Eisenhower\n",
       "479  (In, this, spirit, ,, let, us, together, turn,...  Eisenhower\n",
       "\n",
       "[480 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group into sentences\n",
    "truman_sentence = [[sent, 'Truman']for sent in truman_doc.sents]\n",
    "eisenhower_sentence = [[sent, 'Eisenhower'] for sent in eisenhower_doc.sents ]\n",
    "\n",
    "#Combine the sentences\n",
    "sentences = pd.DataFrame(truman_sentence + eisenhower_sentence)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words(BoW) Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag of words function for each text\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(500)]\n",
    "\n",
    "# Get bags \n",
    "truman_words = bag_of_words(truman_doc)\n",
    "eisenhower_words = bag_of_words(eisenhower_doc)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(truman_words + eisenhower_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length of Common_words:  861\n",
      "\n",
      " {'Admiral', 'unpunished', 'pay', 'equipment', 'hope', 'attack', 'embrace', 'committee', 'yesterday', 'wish', 'function', 'noble', 'opportunity', 'industrial', 'direction', 'alike', 'political', 'safety', 'resolute', 'good', 'democratic', 'devoid', 'Western', 'future', 'waste', 'frequently', 'call', 'enlighten', 'conservation', 'strength', 'calculated', 'sufficient', 'price', 'administrative', 'State', 'require', 'judge', 'dominate', 'fill', 'understanding', 'settlement', 'search', 'defeatism', 'employment', '30', 'American', 'unconscious', 'wisdom', 'worker', 'agricultural', 'shortage', 'humanity', 'match', 'cover', 'dark', 'expire', 'instruct', 'land', 'partial', 'million', 'staggering', 'destroy', 'nery', 'proper', 'vital', 'exchange', 'Mr.', 'beat', 'bitter', 'high', 'local', 'last', 'grow', 'colleague', 'barrier', 'proportion', 'today', 'want', 'population', 'wage', 'improve', 'offer', 'summon', 'join', 'conspiracy', 'insist', 'school', 'problem', 'violate', 'time', 'humility', 'complete', 'duplication', 'San', 'provide', 'session', 'beloved', 'course', 'opponent', 'plan', 'experience', 'defensive', 'God', 'substantial', 'closely', 'strategy', 'lose', 'civilization', 'submission', 'conform', 'Almighty', 'recommendation', 'Allies', 'resource', 'traffic', 'assist', 'learn', 'fate', 'eloquently', 'free', 'misunderstanding', 'dream', 'message', 'achievement', 'find', 'promptly', 'secure', 'immediately', 'States', 'speedy', 'unnecessary', 'longer', 'consideration', 'Aggressors', 'expenditure', 'initiative', 'act', 'inform', 'supreme', 'subject', 'largely', 'hard', 'eloquent', 'thing', 'criminal', 'valiant', 'departed', 'progress', 'difference', 'check', 'task', 'prevent', 'obligation', 'delay', '1950', 'war', 'bomb', 'Conference', 'dollar', 'able', 'invite', 'guilty', 'respect', 'propose', 'nature', 'capacity', 'continued', 'merely', 'design', 'shed', 'geographical', 'shackle', 'congressional', 'press', 'interest', 'proclaim', 'heavy', 'blood', 'system', 'life', 'event', 'pause', 'King', 'citizen', 'thrust', 'tragic', 'cease', 'youth', 'silence', 'decency', '5', 'distant', 'large', 'force', 'race', 'avert', 'friend', 'forward', 'essential', 'related', 'thy', 'possibly', 'fellow', 'sponsor', 'tolerance', 'party', 'confidence', 'end', 'defense', 'Japan', 'forefather', 'abject', 'power', 'harbor', 'regard', 'recently', 'training', 'adequate', 'help', 'Organization', 'guidance', 'order', 'eternal', 'jeopardize', 'business', 'properly', 'inevitably', 'promise', 'significant', 'indicate', 'management', 'America', 'requirement', 'MacArthur', 'horizon', 'liberty', 'fit', 'TRUMAN', 'win', 'service', 'genuine', 'project', 'general', 'develop', 'remain', 'past', 'impossible', 'contain', 'limit', 'endure', 'production', 'attention', 'international', 'period', 'leave', 'move', 'cooperation', 'S.', 'item', 'cause', 'aggression', 'economic', 'involve', 'vestige', 'department', 'long', 'establish', 'energy', 'authority', 'weight', 'creed', 'see', 'share', 'facility', 'particular', 'body', 'fighting', 'constant', 'April', 'authorize', 'obstacle', 'color', 'greatly', 'reverent', 'gradually', 'peaceful', 'slowly', 'shore', 'line', '1', 'bargaining', 'hour', 'legislative', 'review', 'horrible', 'careful', 'toll', 'beginning', 'China', 'woman', 'american', 'clear', 'cherish', 'goal', 'dictate', 'fall', 'breaker', 'united', 'Arnold', 'turn', 'trade', 'continue', 'joint', 'Eisenhower', 'aid', 'small', 'thoughtful', 'affect', 'Americans', 'effective', 'fact', 'fundamental', 'carry', 'die', 'living', 'passage', 'justice', 'grand', 'punish', 'day', 'foundation', 'momentary', 'Communist', '6', 'need', 'Tokyo', 'example', 'benefit', 'productivity', 'unconditional', 'depend', 'dangerous', 'abroad', 'budget', '1954', 'risk', 'firm', 'President', 'ship', 'enact', 'peace', 'receive', '\\n', 'aware', 'protection', 'Seventh', 'armed', 'associate', 'Formosa', 'champion', 'labor', 'respon', 'feel', 'law', 'community', 'correct', 'security', 'economy', 'Marshall', '4', 'surplus', 'protect', 'eliminate', 'nation', 'triumph', 'week', 'enforce', 'number', 'ease', 'effort', 'assign', 'outlook', 'emergency', 'activity', 'threat', 'method', 'mountain', 'process', 'victory', 'basic', 'matter', 'increase', 'fortunately', 'Divine', 'District', '\\n\\n', 'market', 'memory', 'rugged', 'Europe', 'personnel', 'rest', 'sure', 'heroic', 'executive', 'effectively', 'Republic', 'mind', 'governmental', 'go', 'vision', 'government', 'ultimately', 'Nation', 'Security', 'kindly', 'action', 'doubt', 'comfort', 'Labor', 'standard', 'settle', 'unjustified', 'field', 'powerful', 'man', 'courage', 'objective', 'agency', 'ideal', 'possess', 'fatalism', 'complicated', 'right', 'care', 'strong', 'legitimate', 'inadequate', 'rational', 'w', 'National', 'additional', 'sacrifice', 'equitable', 'surely', 'crew', 'experienced', 'leader', 'supply', 'love', 'area', 'look', 'conduct', 'show', 'durable', 'deficit', 'payment', 'remove', 'renew', 'profitable', 'duty', 'single', 'cast', 'strain', 'prosperity', 'religious', 'weapon', 'recommend', 'second', 'make', 'value', 'prove', 'Machi', 'aggressor', 'head', 'liberation', 'immediate', 'defend', 'disaster', 'communist', 'crush', 'growth', 'policy', 'let', 'relation', 'inflation', 'cost', 'retreat', 'proceed', 'ache', 'private', 'self', 'date', 'Leahy', 'like', 'integrate', 'aggressive', 'manufacture', 'United', 'proposal', 'Roosevelt', 'announce', 'result', 'realize', 'Francisco', 'add', 'armistice', 'insure', 'Congress', 'people', 'overwhelming', 'pilot', 'minimum', 'consequently', 'regulation', 'costly', 'safely', 'gratitude', 'regardless', 'debt', 'statutory', 'Speaker', 'current', 'path', 'apply', 'Franklin', 'CONGRESS', 'plot', 'phase', 'General', 'common', 'retain', 'word', 'group', 'earth', 'direct', 'welfare', 'principle', 'term', 'change', 'employ', 'Federal', 'world', 'Malaya', 'belove', 'heart', 'seek', 'gleam', 'friendly', 'mean', 'suffer', 'base', 'measure', 'present', 'machinery', 'place', 'shirk', 'Government', 'legislation', 'expect', 'use', 'tribute', 'military', 'industry', 'misunderstood', 'produce', 'great', 'issue', 'abide', 'individual', 'yield', 'father', 'foreign', 'keep', 'camp', 'inevitable', 'reject', 'reduce', 'ill', 'appropriate', 'lay', 'exist', 'mortal', 'master', 'Korea', 'Nimitz', 'conflict', 'dawn', 'program', '16', 'health', 'honor', 'close', 'break', 'defeat', 'efficient', 'include', 'balance', 'coordination', 'encouragement', 'leadership', 'earnestly', 'moment', 'burden', 'dare', 'Treasury', 'mindful', 'army', 'central', 'earn', 'sense', 'salvation', 'domestic', 'recognize', 'truth', 'maximum', 'member', 'serve', 'farmer', 'greedy', 'support', 'allow', 'preserve', 'enemy', 'domination', 'responsibility', 'manifestly', 'characteristic', 'battlefield', 'relaxation', 'brave', 'struggle', 'PRESIDENT', 'district', 'hopeless', 'fail', 'rock', 'soul', 'tax', 'avoid', 'futile', 'passing', 'Chief', 'investment', 'Soviet', 'doom', 'kind', 'Communists', 'administration', 'Surrender', 'role', 'state', 'human', 'June', 'difficult', 'govern', 'arm', 'unwilling', 'certain', 'armament', 'decide', 'vigilance', 'forget', 'face', 'public', 'global', 'way', 'odd', 'efficiency', 'collective', 'grave', 'equality', 'tremendous', 'resistance', 'd', 'encourage', 'generation', 'Committee', 'immigrant', 'stand', 'justify', 'conscious', 'maintain', 'unite', 'branch', 'complex', 'wise', 'JOINT', 'impunity', 'assume', 'temporary', 'unchanged', 'economical', 'clearly', 'true', 'old', 'anticipate', 'study', 'e', 'tyrant', 'specific', 'defender', 'mark', 'demand', 'idea', 'manifest', 'extend', 'intangible', 'assure', 'untold', 'dmiral', 'Secretary', 'mutual', 'HARRY', 'despair', 'fine', 'affair', 'Russia', 'accordingly', 'Council', 'formulation', 'evidence', 'ADDRESS', 'Hope', 'real', 'shadow', 'deadly', 'fear', 'deeply', 'national', 'Act', 'begin', 'product', '2', 'heritage', 'organization', 'condition', 'Commander', 'civil', 'come', 'follow', 'possible', 'live', 'confident', 'strive', 'honestly', 'total', 'unity', 'Nations', 'unhampered', 'Axis', 'lot', 'technical', 'th', 'meet', 'harmony', 'competitive', 'believe', 'successive', 'infinite', 'spirit', 'permit', 'Navy', 'fiscal', 'repay', 'unquestionably', 'billion', 'terrible', 'appeal', 'development', 'faith', 'special', 'undertake', 'necessity', 'effectiveness', 'office', 'sibility', 'seriously', 'rapidly', 'servant', 'fully', 'build', 'pursue', 'create', 'give', 'far', 'purpose', 'freedom', 'decisive', 'painful', 'tension', 'climate', 'request', 'suffering', 'Fleet', 'pray', 'new', 'work', 'bring', 'devoted', 'Germany', 'fight', 'Department', 'warn', 'play', '3', 'ask', 'Delano', 'chinese', 'ahead', '1945', 'take', 'material', 'worthy', 'integrity', 'step', 't', 'social', 'ghastly', 'muster', 'farm', 'amount', 'depart', 'Defense', 'ally', 'country', 'undying', '1953', 'respite', 'entire', 'shake', 'shrink', 'well', 'control', 'important', 'agriculture', 'taxis', 'home', 'sound', 'enslavement', 'Indochina', 'island', 'oath', 'have', 'backward', 'necessary', 'slavery', 'achieve', 'secret', 'know', 'shall', 'determination', 'yearn', 'Hitler', 'income', 'accept', 'void', 'determine', 'year', 'situation', '\\n \\n'}\n"
     ]
    }
   ],
   "source": [
    "print('\\nLength of Common_words: ', len(common_words))\n",
    "print('\\n', common_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag of words data frame using combined common words and sentences\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Build data frame\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentences in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentences\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admiral</th>\n",
       "      <th>unpunished</th>\n",
       "      <th>pay</th>\n",
       "      <th>equipment</th>\n",
       "      <th>hope</th>\n",
       "      <th>attack</th>\n",
       "      <th>embrace</th>\n",
       "      <th>committee</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>wish</th>\n",
       "      <th>...</th>\n",
       "      <th>Hitler</th>\n",
       "      <th>income</th>\n",
       "      <th>accept</th>\n",
       "      <th>void</th>\n",
       "      <th>determine</th>\n",
       "      <th>year</th>\n",
       "      <th>situation</th>\n",
       "      <th>\\n \\n</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(PRESIDENT, HARRY, S., TRUMAN, 'S, ADDRESS, BE...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(It, is, with, a, heavy, heart, that, I, stand...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Only, yesterday, ,, we, laid, to, rest, the, ...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(At, a, time, like, this, ,, words, are, inade...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, most, eloquent, tribute, would, be, a, r...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 863 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Admiral unpunished pay equipment hope attack embrace committee yesterday  \\\n",
       "0       0          0   0         0    0      0       0         0         0   \n",
       "1       0          0   0         0    0      0       0         0         0   \n",
       "2       0          0   0         0    0      0       0         0         1   \n",
       "3       0          0   0         0    0      0       0         0         0   \n",
       "4       0          0   0         0    0      0       0         0         0   \n",
       "\n",
       "  wish  ... Hitler income accept void determine year situation \\n \\n  \\\n",
       "0    0  ...      0      0      0    0         0    0         0     1   \n",
       "1    0  ...      0      0      0    0         0    0         0     0   \n",
       "2    0  ...      0      0      0    0         0    0         0     0   \n",
       "3    0  ...      0      0      0    0         0    0         0     0   \n",
       "4    0  ...      0      0      0    0         0    0         0     0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (PRESIDENT, HARRY, S., TRUMAN, 'S, ADDRESS, BE...      Truman  \n",
       "1  (It, is, with, a, heavy, heart, that, I, stand...      Truman  \n",
       "2  (Only, yesterday, ,, we, laid, to, rest, the, ...      Truman  \n",
       "3  (At, a, time, like, this, ,, words, are, inade...      Truman  \n",
       "4  (The, most, eloquent, tribute, would, be, a, r...      Truman  \n",
       "\n",
       "[5 rows x 863 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bow features \n",
    "bow = bow_features(sentences, common_words)\n",
    "bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-Features\n",
    "### tdidf (term frequency–inverse document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab sentence level documents in NLTK\n",
    "truman = state_union.sents('1945-Truman.txt')\n",
    "eisenhower = state_union.sents('1953-Eisenhower.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of text\n",
    "truman_list = [\"\".join(sent) for sent in truman]\n",
    "eisenhower_list = [\" \".join(sent) for sent in eisenhower]\n",
    "joined = truman_list + eisenhower_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, \n",
    "                             min_df=2, \n",
    "                             stop_words='english',   \n",
    "                             use_idf=True,\n",
    "                             norm=u'l2', \n",
    "                             smooth_idf=True \n",
    "                            )\n",
    "\n",
    "tfidf = vectorizer.fit_transform(joined).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<465x605 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2333 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Models\n",
    "Evaluate each feature set using cross validation.  Models tested: Logistic Regression, Random Forest, & Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Specify model inputs for each feature set\n",
    "\n",
    "# BoW\n",
    "X_bow = bow.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_bow = bow['text_source']\n",
    "\n",
    "# Tfidf\n",
    "X_tfidf = tfidf\n",
    "Y_tfidf = ['Truman']*len(truman_list) + ['eisenhower']*len(eisenhower_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'Truman',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower',\n",
       " 'eisenhower']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admiral</th>\n",
       "      <th>unpunished</th>\n",
       "      <th>pay</th>\n",
       "      <th>equipment</th>\n",
       "      <th>hope</th>\n",
       "      <th>attack</th>\n",
       "      <th>embrace</th>\n",
       "      <th>committee</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>wish</th>\n",
       "      <th>...</th>\n",
       "      <th>determination</th>\n",
       "      <th>yearn</th>\n",
       "      <th>Hitler</th>\n",
       "      <th>income</th>\n",
       "      <th>accept</th>\n",
       "      <th>void</th>\n",
       "      <th>determine</th>\n",
       "      <th>year</th>\n",
       "      <th>situation</th>\n",
       "      <th>\\n \\n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 861 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Admiral unpunished pay equipment hope attack embrace committee yesterday  \\\n",
       "0       0          0   0         0    0      0       0         0         0   \n",
       "1       0          0   0         0    0      0       0         0         0   \n",
       "2       0          0   0         0    0      0       0         0         1   \n",
       "3       0          0   0         0    0      0       0         0         0   \n",
       "4       0          0   0         0    0      0       0         0         0   \n",
       "\n",
       "  wish  ... determination yearn Hitler income accept void determine year  \\\n",
       "0    0  ...             0     0      0      0      0    0         0    0   \n",
       "1    0  ...             0     0      0      0      0    0         0    0   \n",
       "2    0  ...             0     0      0      0      0    0         0    0   \n",
       "3    0  ...             0     0      0      0      0    0         0    0   \n",
       "4    0  ...             0     0      0      0      0    0         0    0   \n",
       "\n",
       "  situation \\n \\n  \n",
       "0         0     1  \n",
       "1         0     0  \n",
       "2         0     0  \n",
       "3         0     0  \n",
       "4         0     0  \n",
       "\n",
       "[5 rows x 861 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW LogReg Scores:  [0.77319588 0.8125     0.79166667 0.83333333 0.78947368]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Score:  0.8000339120998372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tfidf LogReg Scores: [0.74468085 0.75268817 0.75268817 0.75268817 0.75      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Score: 0.7505490734385724\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#BoW\n",
    "lr = LogisticRegression()\n",
    "lr_bow = lr.fit(X_bow, Y_bow)\n",
    "print('BoW LogReg Scores: ', cross_val_score(lr_bow, X_bow, Y_bow, cv = 5))\n",
    "print('Avg Score: ', np.mean(cross_val_score(lr_bow, X_bow, Y_bow, cv = 5)))\n",
    "\n",
    "#Tfidf\n",
    "lr = LogisticRegression()\n",
    "lr_tfidf = lr.fit(X_bow, Y_bow)\n",
    "print('\\nTfidf LogReg Scores:', cross_val_score(lr_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(lr_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Random Forest Scores:  [0.77319588 0.77083333 0.78125    0.78125    0.81052632]\n",
      "Avg Score: 0.7876851600651112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tfidf Random Forest Scores: [0.71276596 0.65591398 0.76344086 0.68817204 0.72826087]\n",
      "Avg Score: 0.7182203853461052\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "# BoW\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_bow = rfc.fit(X_bow, Y_bow)\n",
    "print('BoW Random Forest Scores: ', cross_val_score(rfc_bow, X_bow, Y_bow, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(rfc_bow, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "# Tfidf\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfc_tfidf = rfc.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Random Forest Scores:', cross_val_score(rfc_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(rfc_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bow Gradient Boosting Scores: [0.71134021 0.80208333 0.77083333 0.75       0.77894737]\n",
      "Avg Score: 0.7668294447458853\n",
      "\n",
      "Tfidf Random Forest Scores: [0.75531915 0.76344086 0.75268817 0.75268817 0.75      ]\n",
      "Avg Score: 0.7548272706474493\n"
     ]
    }
   ],
   "source": [
    "# BoW\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf_bow = clf.fit(X_bow, Y_bow)\n",
    "print('Bow Gradient Boosting Scores:', cross_val_score(clf_bow, X_bow,Y_bow, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(clf_bow, X_bow, Y_bow, cv=5)))\n",
    "\n",
    "# Tfidf\n",
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf_tfidf = clf.fit(X_tfidf, Y_tfidf)\n",
    "print('\\nTfidf Random Forest Scores:', cross_val_score(clf_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(clf_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to increase Accuracy by 5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use BoW to increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag of words function for each text\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n",
    "\n",
    "# Get bags \n",
    "truman_words = bag_of_words(truman_doc)\n",
    "eisenhower_words = bag_of_words(eisenhower_doc)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(truman_words + eisenhower_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admiral</th>\n",
       "      <th>wish</th>\n",
       "      <th>size</th>\n",
       "      <th>alike</th>\n",
       "      <th>safety</th>\n",
       "      <th>devoid</th>\n",
       "      <th>democratic</th>\n",
       "      <th>Western</th>\n",
       "      <th>frequently</th>\n",
       "      <th>conservation</th>\n",
       "      <th>...</th>\n",
       "      <th>have</th>\n",
       "      <th>backward</th>\n",
       "      <th>contingency</th>\n",
       "      <th>secret</th>\n",
       "      <th>November</th>\n",
       "      <th>persist</th>\n",
       "      <th>determine</th>\n",
       "      <th>situation</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(PRESIDENT, HARRY, S., TRUMAN, 'S, ADDRESS, BE...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(It, is, with, a, heavy, heart, that, I, stand...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Only, yesterday, ,, we, laid, to, rest, the, ...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(At, a, time, like, this, ,, words, are, inade...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(The, most, eloquent, tribute, would, be, a, r...</td>\n",
       "      <td>Truman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Admiral wish size alike safety devoid democratic Western frequently  \\\n",
       "0       0    0    0     0      0      0          0       0          0   \n",
       "1       0    0    0     0      0      0          0       0          0   \n",
       "2       0    0    0     0      0      0          0       0          0   \n",
       "3       0    0    0     0      0      0          0       0          0   \n",
       "4       0    0    0     0      0      0          0       0          0   \n",
       "\n",
       "  conservation  ... have backward contingency secret November persist  \\\n",
       "0            0  ...    0        0           0      0        0       0   \n",
       "1            0  ...    0        0           0      0        0       0   \n",
       "2            0  ...    0        0           0      0        0       0   \n",
       "3            0  ...    0        0           0      0        0       0   \n",
       "4            0  ...    0        0           0      0        0       0   \n",
       "\n",
       "  determine situation                                      text_sentence  \\\n",
       "0         0         0  (PRESIDENT, HARRY, S., TRUMAN, 'S, ADDRESS, BE...   \n",
       "1         0         0  (It, is, with, a, heavy, heart, that, I, stand...   \n",
       "2         0         0  (Only, yesterday, ,, we, laid, to, rest, the, ...   \n",
       "3         0         0  (At, a, time, like, this, ,, words, are, inade...   \n",
       "4         0         0  (The, most, eloquent, tribute, would, be, a, r...   \n",
       "\n",
       "  text_source  \n",
       "0      Truman  \n",
       "1      Truman  \n",
       "2      Truman  \n",
       "3      Truman  \n",
       "4      Truman  \n",
       "\n",
       "[5 rows x 1317 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create bow features \n",
    "new_bow = bow_features(sentences, common_words)\n",
    "new_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New_BoW (big) Logistic Regression Scores:  [0.77319588 0.8125     0.79166667 0.83333333 0.78947368]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Score  0.8000339120998372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tfidf LogReg Scores: [0.74468085 0.75268817 0.75268817 0.75268817 0.75      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Score: 0.7505490734385724\n"
     ]
    }
   ],
   "source": [
    "# Make new X and Y inputs\n",
    "X_new_bow = new_bow.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_new_bow = new_bow['text_source']\n",
    "\n",
    "# Rerun BoW\n",
    "lr = LogisticRegression()\n",
    "lr_new_bow = lr.fit(X_new_bow, Y_new_bow)\n",
    "print('New_BoW (big) Logistic Regression Scores: ', cross_val_score(lr_new_bow, X_new_bow, Y_new_bow, cv=5))\n",
    "print('Avg. Score ', np.mean(cross_val_score(lr_new_bow, X_new_bow, Y_new_bow, cv=5)))\n",
    "\n",
    "#Tfidf\n",
    "lr = LogisticRegression()\n",
    "lr_tfidf = lr.fit(X_new_bow, Y_new_bow)\n",
    "print('\\nTfidf LogReg Scores:', cross_val_score(lr_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(lr_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Increase common word to 2000 and include punctuation and stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include punctuation\n",
    "# Create bag of words function for each text\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text]\n",
    "    \n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "\n",
    "# Get bags \n",
    "truman_words = bag_of_words(truman_doc)\n",
    "eisenhower_words = bag_of_words(eisenhower_doc)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(truman_words + eisenhower_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-22d96415a168>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create bow features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnew_bow_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbow_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommon_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-0537a38a83f7>\u001b[0m in \u001b[0;36mbow_features\u001b[1;34m(sentences, common_words)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# Populate the row with word counts.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;31m# actually do the set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36msetitem\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"setitem\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36msetitem\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[1;31m# coerce and try to infer the dtypes of the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_coerce_and_cast_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    942\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_try_coerce_and_cast_result\u001b[1;34m(self, result, dtype)\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_try_coerce_and_cast_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_coerce_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_cast_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_try_cast_result\u001b[1;34m(self, result, dtype)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[1;31m# may need to change the dtype here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_downcast_to_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_coerce_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mmaybe_downcast_to_dtype\u001b[1;34m(result, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"infer\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0minferred_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minferred_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"boolean\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"bool\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create bow features \n",
    "new_bow_1 = bow_features(sentences, common_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new X and Y inputs\n",
    "X_new_bow = new_bow_1.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_new_bow = new_bow_1['text_source']\n",
    "\n",
    "# Rerun BoW\n",
    "lr = LogisticRegression()\n",
    "lr_new_bow = lr.fit(X_new_bow, Y_new_bow)\n",
    "print('New_BoW (big) Logistic Regression Scores: ', cross_val_score(lr_new_bow, X_new_bow, Y_new_bow, cv=5))\n",
    "print('Avg. Score ', np.mean(cross_val_score(lr_new_bow, X_new_bow, Y_new_bow, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use tfidf to increase accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.80, \n",
    "                             min_df=4, \n",
    "                             stop_words='english',   \n",
    "                             use_idf=True,\n",
    "                             norm=u'l2', \n",
    "                             smooth_idf=True \n",
    "                            )\n",
    "\n",
    "tfidf = vectorizer.fit_transform(joined).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Tfidf\n",
    "lr = LogisticRegression()\n",
    "lr_tfidf = lr.fit(X_bow, Y_bow)\n",
    "print('\\nTfidf LogReg Scores:', cross_val_score(lr_tfidf, X_tfidf, Y_tfidf, cv=5))\n",
    "print('Avg Score:', np.mean(cross_val_score(lr_tfidf, X_tfidf, Y_tfidf, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick A Model and Try to Increase Accuracy by 5%\n",
    "\n",
    "__Model: Logistic Regression Using BoW Feature Set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-6840675558e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create bow features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbig_bow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbow_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommon_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-0537a38a83f7>\u001b[0m in \u001b[0;36mbow_features\u001b[1;34m(sentences, common_words)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# Populate the row with word counts.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;31m# actually do the set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36msetitem\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"setitem\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36msetitem\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[1;31m# coerce and try to infer the dtypes of the result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 941\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_coerce_and_cast_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    942\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_try_coerce_and_cast_result\u001b[1;34m(self, result, dtype)\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_try_coerce_and_cast_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_coerce_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_cast_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_try_cast_result\u001b[1;34m(self, result, dtype)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[1;31m# may need to change the dtype here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_downcast_to_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_coerce_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\catanEnv\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mmaybe_downcast_to_dtype\u001b[1;34m(result, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"infer\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0minferred_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minferred_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"boolean\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"bool\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create bow features \n",
    "big_bow = bow_features(sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new X and Y inputs\n",
    "X_big_bow = big_bow.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_big_bow = big_bow['text_source']\n",
    "\n",
    "# Rerun BoW\n",
    "lr = LogisticRegression()\n",
    "lr_big_bow = lr.fit(X_big_bow, Y_big_bow)\n",
    "print('BoW (big) Logistic Regression Scores: ', cross_val_score(lr_big_bow, X_big_bow, Y_big_bow, cv=5))\n",
    "print('Avg. Score ', np.mean(cross_val_score(lr_big_bow, X_big_bow, Y_big_bow, cv=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a bigger bag of words actually made the average score get worse by about 1%.  Try out another method - include punctuation in BoW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update function, go back to 500 most common words and add in punctuation\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # filter out punctuation and stop words\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_stop]\n",
    "                   \n",
    "    # Return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(500)]\n",
    "\n",
    "# Get bags \n",
    "bush_words = bag_of_words(bush_doc)\n",
    "clinton_words = bag_of_words(clinton_doc)\n",
    "\n",
    "# Combine bags to create common set of unique words\n",
    "common_words = set(bush_words + clinton_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bow features \n",
    "bow = bow_features(sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regenerate model features\n",
    "X_bow = bow.drop(['text_sentence', 'text_source'], 1)\n",
    "Y_bow = bow['text_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun model\n",
    "lr = LogisticRegression(\n",
    "    )\n",
    "lr_bow = lr.fit(X_bow, Y_bow)\n",
    "print('BoW #3 - Logistic Regression Scores: ', cross_val_score(lr_bow, X_bow, Y_bow, cv=5))\n",
    "print('Avg. Score ', np.mean(cross_val_score(lr_bow, X_bow, Y_bow, cv=5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
