{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Make Your Network\n",
    "For this challenge you have two options for how to use neural networks . Choose one of the following:\n",
    "\n",
    "Use RBM to perform feature extraction on an image-based dataset that you find or create. If you go this route, present the features you extract and explain why this is a useful feature extraction method in the context you’re operating in. DO NOT USE either the MNIST digit recognition database or the iris data set. They’ve been worked on in very public ways very very many times and the code is easily available. (However, that code could be a useful resource to refer to). _OR_,\n",
    "\n",
    "Create a multi-layer perceptron neural network model to predict on a labeled dataset of your choosing. Compare this model to either a boosted tree or a random forest model and describe the relative tradeoffs between complexity and accuracy. Be sure to vary the hyperparameters of your MLP!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Image if it is Cat or Dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising the CNN\n",
    "classifier = Sequential()\n",
    "#Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Adding a second convolution layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 - Flattening \n",
    "classifier.add(Flatten())\n",
    "\n",
    "#Step 4- Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  shear_range = 0.2,\n",
    "                                  zoom_range =0.2,\n",
    "                                  horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('C:/Users/catan/Documents/data_set/training_set', \n",
    "                                                target_size = (64, 64), \n",
    "                                                batch_size = 32,\n",
    "                                                class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2022 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_set = train_datagen.flow_from_directory('C:/Users/catan/Documents/data_set/test_set', \n",
    "                                                target_size = (64, 64), \n",
    "                                                batch_size = 32,\n",
    "                                                class_mode = 'binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#for meantime we can change to 4000 picture and 10 for learning process but in reality we to run all the pictures.\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000,\n",
    "                        epochs = 25,\n",
    "                        validation_data = test_set,\n",
    "                        validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0818 23:06:50.833646 13200 deprecation_wrapper.py:119] From C:\\Users\\catan\\.conda\\envs\\catanEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 546s 137ms/step - loss: 0.4742 - acc: 0.7638 - val_loss: 0.5038 - val_acc: 0.7750\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 549s 137ms/step - loss: 0.2837 - acc: 0.8772 - val_loss: 0.6073 - val_acc: 0.7875\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 538s 135ms/step - loss: 0.1806 - acc: 0.9265 - val_loss: 0.6505 - val_acc: 0.7812\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 542s 135ms/step - loss: 0.1191 - acc: 0.9545 - val_loss: 0.7791 - val_acc: 0.8156\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 542s 136ms/step - loss: 0.0873 - acc: 0.9674 - val_loss: 0.7981 - val_acc: 0.8125\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 546s 136ms/step - loss: 0.0695 - acc: 0.9745 - val_loss: 1.1468 - val_acc: 0.7625\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 554s 138ms/step - loss: 0.0552 - acc: 0.9799 - val_loss: 1.1464 - val_acc: 0.8027\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 555s 139ms/step - loss: 0.0488 - acc: 0.9827 - val_loss: 0.9997 - val_acc: 0.8187\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 551s 138ms/step - loss: 0.0413 - acc: 0.9856 - val_loss: 1.5317 - val_acc: 0.7500\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 554s 139ms/step - loss: 0.0371 - acc: 0.9871 - val_loss: 1.1816 - val_acc: 0.8063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dc23305888>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for meantime we can change to 4000 picture and 10 for learning process but in reality we to run all the pictures.\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 4000,\n",
    "                        epochs = 10,\n",
    "                        validation_data = test_set,\n",
    "                        validation_steps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "#Part 3 - Making new predictions\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('C:/Users/catan/Documents/data_set/test_set/cats/cat.4003.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "#Part 3 - Making new predictions\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('C:/Users/catan/Documents/data_set/test_set/cats/cat.4005.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "#Part 3 - Making new predictions\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('C:/Users/catan/Documents/data_set/test_set/dogs/dog.4003.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "#Part 3 - Making new predictions\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('C:/Users/catan/Documents/data_set/test_set/dogs/dog.4002.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
